{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUDA_Matrix_Multiplication.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-malte/Simple-LP1-Codes/blob/master/HPC2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG83fqWNsOz2",
        "colab_type": "text"
      },
      "source": [
        "##Select Runtime as GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od_h5OFyWUOu",
        "colab_type": "code",
        "outputId": "12e8e5b7-de8b-489e-ca85-0c4df16b26f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV09WaRbt8CG",
        "colab_type": "text"
      },
      "source": [
        "##Note\n",
        "\"//n\" has been used  for newline  and not \"/n\" cause the code is saved to a file. Hence I need to escape the /n so that it is not saved as newline in the file, but with the actual text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oSs5YarocyP",
        "colab_type": "text"
      },
      "source": [
        "##CUDA code explained\n",
        "1. M, N are n*n matrices, P is output matrix\n",
        "2. The output of each element in P is calculated by individual threads\n",
        "3. All matrices (M, N, P) are stored in row-major format.\n",
        "4. All variable names starting with d_ are on device (on this code)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvvfu1PvWX8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "code = \"\"\"\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void matmul(int* M, int* N, int* P, int* width)\n",
        "{\n",
        "  int row = blockIdx.x;\n",
        "  int col = threadIdx.x;\n",
        "  P[row*(*width)+col]=0;    //set the output of current element to 0\n",
        "  for(int i=0; i<*width; i++)\n",
        "  {\n",
        "    P[row*(*width)+col] += M[row*(*width)+i]*N[i*(*width)+col]; //I've converted the general A[row][col] to A[row*width+col]\n",
        "  }                                                             //because of the row major format\n",
        "}\n",
        "//d_xyz in my code means xyz is on the device\n",
        "int main()\n",
        "{\n",
        "  int width = 4;  //width of n*n matrix\n",
        "  int* d_width;\n",
        "  cudaMalloc(&d_width, sizeof(int));\n",
        "  //copy width\n",
        "  cudaMemcpy(d_width, &width, sizeof(int), cudaMemcpyHostToDevice);\n",
        "  \n",
        "  //define input matrices\n",
        "  int M[width][width] = {{5,7,9,10},\n",
        "                        {2,3,3,8},  \n",
        "                        {8,10,2,3},\n",
        "                        {3,3,4,8}\n",
        "                        };\n",
        "\n",
        "  int N[width][width] = {{3,10,12,18},\n",
        "                        {12,1,4,9},\n",
        "                        {9,10,12,2},\n",
        "                        {3,12,4,10}};\n",
        "  \n",
        "  //declare output matrix on host side\n",
        "  int P[width][width];\n",
        "\n",
        "  int *d_M, *d_N, *d_P;\n",
        "  cudaMalloc(&d_M, sizeof(int)*width*width);\n",
        "  cudaMalloc(&d_N, sizeof(int)*width*width);\n",
        "  cudaMalloc(&d_P, sizeof(int)*width*width);\n",
        "\n",
        "  //copy matrices to GPU\n",
        "  cudaMemcpy(d_M, M, sizeof(int)*width*width, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_N, N, sizeof(int)*width*width, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_P, P, sizeof(int)*width*width, cudaMemcpyHostToDevice);\n",
        "  \n",
        "  matmul<<<width, width>>>(d_M, d_N, d_P, d_width);     \n",
        "  cudaMemcpy(P, d_P, sizeof(int)*width*width, cudaMemcpyDeviceToHost);\n",
        "  \n",
        "  cout<<\"The output is:\\\\n\";\n",
        "  for(int i=0; i<width; i++)\n",
        "  {\n",
        "    for(int j=0; j<width; j++)\n",
        "    {\n",
        "      cout<<P[i][j]<<\" \";\n",
        "    }\n",
        "    cout<<\"\\\\n\";\n",
        "  }\n",
        "  cudaFree(d_M);\n",
        "  cudaFree(d_N);\n",
        "  cudaFree(d_P);\n",
        "  return 0;\n",
        "}\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-sv3mWlWvd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_file = open(\"code.cu\", \"w\")\n",
        "text_file.write(code)\n",
        "text_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWGAyAbzXGQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc code.cu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dozKqOBWXSPI",
        "colab_type": "code",
        "outputId": "484b6faa-b719-4102-dc85-0c4c7d5d52bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!./a.out"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The output is:\n",
            "210 267 236 271 \n",
            "93 149 104 149 \n",
            "171 146 172 268 \n",
            "105 169 128 169 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA9TUipxpMoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "db7cab05-3704-43e4-deb2-57c18bb2dd80"
      },
      "source": [
        "!nvprof ./a.out"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==2494== NVPROF is profiling process 2494, command: ./a.out\n",
            "The output is:\n",
            "210 267 236 271 \n",
            "93 149 104 149 \n",
            "171 146 172 268 \n",
            "105 169 128 169 \n",
            "==2494== Profiling application: ./a.out\n",
            "==2494== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   43.51%  7.2960us         1  7.2960us  7.2960us  7.2960us  matmul(int*, int*, int*, int*)\n",
            "                   42.18%  7.0720us         4  1.7680us  1.5680us  2.3040us  [CUDA memcpy HtoD]\n",
            "                   14.31%  2.4000us         1  2.4000us  2.4000us  2.4000us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.13%  137.16ms         4  34.290ms  8.0030us  137.13ms  cudaMalloc\n",
            "                    0.39%  538.83us         1  538.83us  538.83us  538.83us  cuDeviceTotalMem\n",
            "                    0.21%  295.91us        96  3.0820us     155ns  134.06us  cuDeviceGetAttribute\n",
            "                    0.14%  187.18us         1  187.18us  187.18us  187.18us  cudaLaunchKernel\n",
            "                    0.09%  121.28us         5  24.255us  11.103us  35.635us  cudaMemcpy\n",
            "                    0.03%  36.255us         3  12.085us  8.0340us  19.423us  cudaFree\n",
            "                    0.01%  18.869us         1  18.869us  18.869us  18.869us  cuDeviceGetName\n",
            "                    0.00%  3.6830us         1  3.6830us  3.6830us  3.6830us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8960us         3     632ns     191ns  1.1800us  cuDeviceGetCount\n",
            "                    0.00%  1.0950us         2     547ns     228ns     867ns  cuDeviceGet\n",
            "                    0.00%     337ns         1     337ns     337ns     337ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}